{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3c32ee4",
   "metadata": {},
   "source": [
    "# NII Trainer: Liver and Tumor Segmentation\n",
    "\n",
    "This notebook demonstrates how to use the NII Trainer package for medical image segmentation.\n",
    "The package allows you to train cascaded neural networks on NIfTI data for tasks like\n",
    "liver and tumor segmentation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7574cebe",
   "metadata": {},
   "source": [
    "## 1. Import Required Modules\n",
    "\n",
    "First, let's import the core functions from our package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d3e7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Import the main module functions\n",
    "\n",
    "\n",
    "from main import (\n",
    "    create_liver_tumor_config,\n",
    "    run_liver_tumor_segmentation,\n",
    "    get_default_curriculum_params,\n",
    "    create_custom_experiment\n",
    ")\n",
    "\n",
    "# Import some internal modules for more advanced usage\n",
    "from nii_trainer.configs.config import TrainerConfig, DataConfig, CascadeConfig\n",
    "from nii_trainer.utils import Experiment, setup_logger\n",
    "from nii_trainer.visualization import SegmentationVisualizer\n",
    "\n",
    "# Verify directories\n",
    "volume_dir = \"volume_pt1\"\n",
    "segmentation_dir = \"segmentations\"\n",
    "\n",
    "print(f\"Volume directory exists: {os.path.exists(volume_dir)}\")\n",
    "print(f\"Segmentation directory exists: {os.path.exists(segmentation_dir)}\")\n",
    "print(f\"Number of volume files: {len(list(Path(volume_dir).glob('*.nii')))}\")\n",
    "print(f\"Number of segmentation files: {len(list(Path(segmentation_dir).glob('*.nii')))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8340c1fa",
   "metadata": {},
   "source": [
    "## 2. Basic Usage: Running a Complete Experiment\n",
    "\n",
    "The simplest way to use the package is with the high-level `run_liver_tumor_segmentation` function,\n",
    "which handles the entire pipeline from data preprocessing to model training and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08a9371",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running a basic experiment - this will process data, train, and evaluate\n",
    "# Note: This can take a long time to run, especially on CPU\n",
    "# You can set process_data=False if you've already processed the data\n",
    "\n",
    "experiment = run_liver_tumor_segmentation(\n",
    "    volume_dir=\"../volume_pt1\",\n",
    "    segmentation_dir=\"../segmentations\",\n",
    "    output_dir=\"../experiments\",\n",
    "    experiment_name=\"liver_tumor_test\",\n",
    "    process_data=True,        # Set to False to skip data processing\n",
    "    force_overwrite=False,    # Set to True to force reprocessing\n",
    "    use_curriculum=True,      # Use curriculum learning approach\n",
    "     img_size=(512, 512),      # Target image size\n",
    "     batch_size=16,            # Batch size for training\n",
    "     slice_step=1,             # Use every slice\n",
    "     skip_empty=False,         # Include slices without annotations\n",
    "     epochs=100                # Number of training epochs\n",
    " )\n",
    "\n",
    "# Uncomment the above code to run a full experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9701c154",
   "metadata": {},
   "source": [
    "## 3. Data Processing Only\n",
    "\n",
    "If you want to just process the NIfTI data without training a model, \n",
    "you can create an experiment and call the `process_data` method directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a230fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a configuration\n",
    "config = create_liver_tumor_config(\n",
    "    volume_dir=\"volume_pt1\",\n",
    "    img_size=(512, 512),\n",
    "    window_width=180,\n",
    "    window_level=50,\n",
    "    skip_empty=False,\n",
    "    slice_step=1\n",
    ")\n",
    "\n",
    "# Create an experiment\n",
    "experiment = create_custom_experiment(\n",
    "    config=config,\n",
    "    experiment_name=\"data_processing_only\",\n",
    "    base_dir=\"experiments\"\n",
    ")\n",
    "\n",
    "# Process just a few volumes for demonstration (set to None for all)\n",
    "# The code below is commented out to prevent accidental execution\n",
    "# Since it can take a while to process all the volumes\n",
    "\n",
    "# experiment.process_data(\n",
    "#     volume_dir=\"volume_pt1\",\n",
    "#     segmentation_dir=\"segmentations\",\n",
    "#     force_overwrite=False  # Set to True to reprocess existing data\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "986e2f5c",
   "metadata": {},
   "source": [
    "## 4. Creating Custom Configurations\n",
    "\n",
    "You can customize the training configuration by modifying parameters\n",
    "or creating a completely custom configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3dc30ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a custom configuration with modified parameters\n",
    "custom_config = create_liver_tumor_config(\n",
    "    volume_dir=\"volume_pt1\",\n",
    "    output_dir=\"processed_data_custom\",\n",
    "    img_size=(384, 384),  # Different image size\n",
    "    batch_size=8,         # Smaller batch size\n",
    "    window_width=200,     # Different window width\n",
    "    window_level=40,      # Different window level\n",
    "    slice_step=2,         # Take every other slice\n",
    "    train_val_test_split=(0.7, 0.15, 0.15),  # Different split ratio\n",
    "    learning_rate=5e-5,   # Lower learning rate\n",
    "    epochs=150            # More epochs\n",
    ")\n",
    "\n",
    "# Print the configuration to verify\n",
    "print(f\"Image size: {custom_config.data.img_size}\")\n",
    "print(f\"Batch size: {custom_config.data.batch_size}\")\n",
    "print(f\"Window parameters: {custom_config.data.window_params}\")\n",
    "print(f\"Slice step: {custom_config.data.slice_step}\")\n",
    "print(f\"Learning rate: {custom_config.training.learning_rate}\")\n",
    "print(f\"Epochs: {custom_config.training.epochs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ec8b69",
   "metadata": {},
   "source": [
    "## 5. Working with Curriculum Learning\n",
    "\n",
    "Curriculum learning is a training strategy where the model first learns simpler tasks\n",
    "before progressing to more complex ones. In our case, this means first learning to\n",
    "segment the liver, then learning to segment tumors within the liver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb826043",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get default curriculum parameters\n",
    "curriculum_params = get_default_curriculum_params()\n",
    "print(\"Default curriculum parameters:\")\n",
    "print(f\"Stage schedule: {curriculum_params['stage_schedule']}\")\n",
    "print(f\"Learning rates: {curriculum_params['learning_rates']}\")\n",
    "print(f\"Stage freezing: {curriculum_params['stage_freezing']}\")\n",
    "\n",
    "# Create custom curriculum parameters\n",
    "custom_curriculum = {\n",
    "    'stage_schedule': [\n",
    "        (0, 30),  # Train liver stage for 30 epochs\n",
    "        (1, 70)   # Add tumor stage for 70 more epochs\n",
    "    ],\n",
    "    'learning_rates': [2e-3, 1e-4],  # Different learning rates\n",
    "    'stage_freezing': [False, True]  # Same freezing strategy\n",
    "}\n",
    "\n",
    "print(\"\\nCustom curriculum parameters:\")\n",
    "print(f\"Stage schedule: {custom_curriculum['stage_schedule']}\")\n",
    "print(f\"Learning rates: {custom_curriculum['learning_rates']}\")\n",
    "print(f\"Stage freezing: {custom_curriculum['stage_freezing']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90df8ae",
   "metadata": {},
   "source": [
    "## 6. Advanced Usage: Working with the Experiment API\n",
    "\n",
    "For more control over the training process, you can use the Experiment API directly.\n",
    "This allows you to access the model, trainer, and datasets for custom analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeaa0c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create experiment with custom configuration\n",
    "experiment = create_custom_experiment(\n",
    "    config=custom_config,\n",
    "    experiment_name=\"advanced_example\",\n",
    "    base_dir=\"experiments\"\n",
    ")\n",
    "\n",
    "# Process data (commented out to prevent accidental execution)\n",
    "# experiment.process_data(\n",
    "#     volume_dir=\"volume_pt1\",\n",
    "#     segmentation_dir=\"segmentations\",\n",
    "#     force_overwrite=False\n",
    "# )\n",
    "\n",
    "# Setup data pipeline\n",
    "# datasets, dataloaders = experiment.setup_data_pipeline()\n",
    "\n",
    "# Setup model\n",
    "# model, trainer = experiment.setup_model()\n",
    "\n",
    "# Train model (with or without curriculum)\n",
    "# experiment.train(curriculum=True, curriculum_params=custom_curriculum)\n",
    "\n",
    "# Evaluate model\n",
    "# metrics = experiment.evaluate()\n",
    "\n",
    "# Generate visualizations\n",
    "# experiment.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7bcef10",
   "metadata": {},
   "source": [
    "## 7. Visualization\n",
    "\n",
    "After training, you can visualize the segmentation results using the SegmentationVisualizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6aee0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load an experiment (assuming you've already trained one)\n",
    "# Replace \"liver_tumor_test\" with your experiment name\n",
    "\n",
    "# from nii_trainer.utils import Experiment\n",
    "# experiment_name = \"liver_tumor_test\"\n",
    "# saved_experiment = Experiment(\n",
    "#     config=create_liver_tumor_config(experiment_name=experiment_name),\n",
    "#     experiment_name=experiment_name,\n",
    "#     base_dir=\"experiments\"\n",
    "# )\n",
    "# \n",
    "# # Setup the data pipeline to load the datasets\n",
    "# datasets, dataloaders = saved_experiment.setup_data_pipeline()\n",
    "# \n",
    "# # Setup the model to load the trained weights\n",
    "# model, trainer = saved_experiment.setup_model()\n",
    "# \n",
    "# # Create a visualizer\n",
    "# visualizer = SegmentationVisualizer(\n",
    "#     model=model,\n",
    "#     dataloader=dataloaders[\"val\"],\n",
    "#     class_names=[\"background\", \"liver\", \"tumor\"],\n",
    "#     device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# )\n",
    "# \n",
    "# # Display a few examples\n",
    "# visualizer.display_batch(num_samples=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe0c629",
   "metadata": {},
   "source": [
    "## 8. Customizing Data Processing\n",
    "\n",
    "For more control over data processing, you can use the BatchProcessor directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54110247",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the batch processor\n",
    "from nii_trainer.data import BatchProcessor\n",
    "\n",
    "# Create a custom processor with specific parameters\n",
    "custom_processor = BatchProcessor(\n",
    "    img_size=(512, 512),\n",
    "    window_params={\"window_width\": 180, \"window_level\": 50},\n",
    "    skip_empty=True,  # Skip empty slices\n",
    "    slice_step=2,     # Take every other slice\n",
    "    train_val_test_split=(0.8, 0.1, 0.1),  # Different split ratios\n",
    "    segmentation_pattern=\"segmentation-{}.nii\",  # Pattern for segmentation files\n",
    "    volume_pattern=\"volume-{}.nii\"  # Pattern for volume files\n",
    ")\n",
    "\n",
    "# Process only a specific subset of volumes (commented out to prevent execution)\n",
    "# processed_pairs = custom_processor.process_batch(\n",
    "#     volume_dir=\"volume_pt1\",\n",
    "#     segmentation_dir=\"segmentations\",\n",
    "#     output_dir=\"custom_processed_data\",\n",
    "#     max_volumes=5,  # Only process the first 5 volumes\n",
    "#     force_overwrite=False\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7993ece",
   "metadata": {},
   "source": [
    "## 9. Conclusion\n",
    "\n",
    "This notebook demonstrated the key features of the NII Trainer package for medical image segmentation.\n",
    "You can customize the configuration, preprocessing, training strategy, and visualization to suit your needs.\n",
    "\n",
    "For more details, refer to the package documentation and source code."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
